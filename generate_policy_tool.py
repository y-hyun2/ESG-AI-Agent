# generate_policy_tool.py
import os

BASE = "src/tools/policy_tool"

FILES = {
    "__init__.py": "",
    "policy_tool.py": """
from langchain.tools import tool
from .summarizers.policy_summarizer import PolicySummarizer
from .comparators.policy_comparator import PolicyComparator
from .recommenders.policy_recommender import PolicyRecommender
from .evaluators.policy_evaluator import PolicyEvaluator


class PolicyTool:
    @tool
    def summarize_policy(self, text: str) -> str:
        return PolicySummarizer().summarize(text)

    @tool
    def compare_policies(self, policy_a: str, policy_b: str):
        return PolicyComparator().compare(policy_a, policy_b)

    @tool
    def recommend_policy(self, text: str):
        return PolicyRecommender().recommend(text)

    @tool
    def evaluate_policy(self, text: str):
        return PolicyEvaluator().evaluate(text)
""",
}

DIRS = {
    "parsers": {
        "__init__.py": "",
        "base_parser.py": """
class BasePolicyParser:
    def parse(self, text: str) -> dict:
        raise NotImplementedError
""",
        "policy_parser.py": """
from .base_parser import BasePolicyParser

class PolicyParser(BasePolicyParser):
    def parse(self, text: str) -> dict:
        # TODO: Add real parsing logic
        return {"sections": [], "requirements": []}
""",
        "requirement_extractor.py": """
class RequirementExtractor:
    def extract(self, parsed_doc: dict):
        # TODO: Real extraction logic
        return []
""",
    },
    "summarizers": {
        "__init__.py": "",
        "policy_summarizer.py": """
from ..prompts.summarizer_prompts import SUMMARIZE_PROMPT
from langchain_openai import ChatOpenAI

class PolicySummarizer:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4o-mini")

    def summarize(self, text: str) -> str:
        return self.llm.invoke(SUMMARIZE_PROMPT.format(text=text))
""",
    },
    "comparators": {
        "__init__.py": "",
        "policy_comparator.py": """
from ..prompts.comparator_prompts import COMPARE_PROMPT
from langchain_openai import ChatOpenAI

class PolicyComparator:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4o-mini")

    def compare(self, a: str, b: str):
        return self.llm.invoke(COMPARE_PROMPT.format(policy_a=a, policy_b=b))
""",
    },
    "recommenders": {
        "__init__.py": "",
        "policy_recommender.py": """
from ..prompts.recommender_prompts import RECOMMEND_PROMPT
from langchain_openai import ChatOpenAI

class PolicyRecommender:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4o-mini")

    def recommend(self, text: str):
        return self.llm.invoke(RECOMMEND_PROMPT.format(text=text))
""",
    },
    "evaluators": {
        "__init__.py": "",
        "policy_evaluator.py": """
from ..prompts.evaluator_prompts import EVALUATE_PROMPT
from langchain_openai import ChatOpenAI

class PolicyEvaluator:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4o-mini")

    def evaluate(self, text: str):
        return self.llm.invoke(EVALUATE_PROMPT.format(text=text))
""",
    },
    "prompts": {
        "__init__.py": "",
        "summarizer_prompts.py": """
SUMMARIZE_PROMPT = \"\"\"
ë‹¹ì‹ ì€ ESG ì •ì±… ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ì •ì±… ë¬¸ì„œë¥¼ í•µì‹¬ í•­ëª© ì¤‘ì‹¬ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”:

{text}
\"\"\"
""",
        "comparator_prompts.py": """
COMPARE_PROMPT = \"\"\"
ë‘ ì •ì±… ë¬¸ì„œë¥¼ ë¹„êµí•˜ì—¬ ë‹¤ìŒì„ ë„ì¶œí•˜ì„¸ìš”:

1. ê³µí†µì 
2. ì°¨ì´ì 
3. ëˆ„ë½ ìš”ì†Œ(Gap)
4. ê°œì„  ê¶Œê³ ì‚¬í•­

[ì •ì±… A]
{policy_a}

[ì •ì±… B]
{policy_b}
\"\"\"
""",
        "evaluator_prompts.py": """
EVALUATE_PROMPT = \"\"\"
ì •ì±… ë¬¸ì„œë¥¼ ì•„ë˜ ê¸°ì¤€ì— ë”°ë¼ í‰ê°€í•˜ì„¸ìš”:

- ëª…í™•ì„±
- ì¸¡ì • ê°€ëŠ¥ì„±
- ì±…ì„ì„±
- íˆ¬ëª…ì„±
- ê¸€ë¡œë²Œ ê¸°ì¤€ ì •í•©ì„±

ì¶œë ¥ì€ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”.

{text}
\"\"\"
""",
        "recommender_prompts.py": """
RECOMMEND_PROMPT = \"\"\"
ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ESG ì •ì±… ê°œì„ ì•ˆì„ ì œì•ˆí•˜ì„¸ìš”.

1. ë¶€ì¡±í•œ í•­ëª©
2. ê°œì„  í•„ìš” ì´ìœ 
3. ê¸€ë¡œë²Œ ê¸°ì¤€ ê¸°ë°˜ í…œí”Œë¦¿ ì œì•ˆ

{text}
\"\"\"
""",
    },
    "utils": {
        "__init__.py": "",
        "schema.py": """
from pydantic import BaseModel
from typing import List, Optional

class PolicySection(BaseModel):
    title: str
    content: str

class PolicyDocument(BaseModel):
    sections: List[PolicySection]
    requirements: List[str] = []
""",
        "scoring.py": """
def cosine_similarity(a, b):
    from numpy import dot
    from numpy.linalg import norm
    return dot(a, b) / (norm(a) * norm(b))
""",
    },
}


def ensure_dir(path):
    if not os.path.exists(path):
        os.makedirs(path)


def write_file(path, content):
    with open(path, "w", encoding="utf-8") as f:
        f.write(content.strip() + "\n")


def main():
    print(f"ğŸ“ ìƒì„± ì‹œì‘: {BASE}")
    ensure_dir(BASE)

    # top-level files
    for filename, content in FILES.items():
        write_file(os.path.join(BASE, filename), content)
        print("  âœ”", filename)

    # subdirectories
    for folder, files in DIRS.items():
        folder_path = os.path.join(BASE, folder)
        ensure_dir(folder_path)
        print("ğŸ“", folder)
        for filename, content in files.items():
            write_file(os.path.join(folder_path, filename), content)
            print("   âœ”", filename)

    print("\nğŸš€ policy_tool ì „ì²´ êµ¬ì¡° ìƒì„± ì™„ë£Œ!")


if __name__ == "__main__":
    main()
